{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification Using Individual Replicas\n",
    "This notebook analyzes the quality of the classifiers resulting from training on individual replicas of read counts rather than averaged values. Data are adjusted for library size and gene length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import init\n",
    "from common import constants as cn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "from common_python.classifier import classifier_ensemble\n",
    "from common_python.classifier import classifier_collection\n",
    "from common_python.classifier.classifier_ensemble_random_forest import ClassifierEnsembleRandomForest\n",
    "from common_python.plots import util_plots as common_plots\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Replica Data\n",
    "The following shows the extent to which replicas agree with the tranary values that are assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareDFValues(df1, df2, title):\n",
    "    RANGE = [-8, 8]\n",
    "    plt.figure()\n",
    "    arr1 = df1.values.flatten()\n",
    "    arr2 = df2.values.flatten()\n",
    "    plt.scatter(arr1, arr2)\n",
    "    # Define region of 0 values\n",
    "    plt.plot([-1, -1], [-1, 1], color=\"b\")\n",
    "    plt.plot([1, 1], [-1, 1], color=\"b\")\n",
    "    plt.plot([-1, 1], [-1, -1], color=\"b\")\n",
    "    plt.plot([-1, 1], [1, 1], color=\"b\")\n",
    "    # Define region of 1 values\n",
    "    plt.plot([1, 1], [1, RANGE[1]], color=\"b\")\n",
    "    plt.plot([1, RANGE[1]], [1, 1], color=\"b\")\n",
    "    # Define region of -1 values\n",
    "    plt.plot([-1, -1], [-1, RANGE[0]], color=\"b\")\n",
    "    plt.plot([-1, RANGE[0]], [-1, -1], color=\"b\")\n",
    "    plt.plot(RANGE, RANGE, color=\"r\")\n",
    "    plt.title(title)\n",
    "    \n",
    "provider = DataProvider()\n",
    "provider.do()\n",
    "dfs = []\n",
    "for idx in range(3):\n",
    "      dfs.append(provider.dfs_adjusted_read_count_wrtT0_log2[idx])\n",
    "compareDFValues(dfs[0], dfs[1], \"0 vs 1\")\n",
    "compareDFValues(dfs[0], dfs[2], \"0 vs 2\")\n",
    "compareDFValues(dfs[1], dfs[2], \"1 vs 2\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM With Replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clfEval(is_averaged, high_rank=15, ensemble_size=50, is_randomize=False, num_iterations=10):\n",
    "    trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_averaged)\n",
    "    df_X = trinary.df_X.copy()\n",
    "    df_X.columns = trinary.features\n",
    "    ser_y = trinary.ser_y.copy()\n",
    "    if is_randomize:\n",
    "        # Randomize the relationship between features and state\n",
    "        df_X = df_X.sample(frac=1)\n",
    "        ser_y = ser_y.sample(frac=1)\n",
    "    #\n",
    "    svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "        classifier_ensemble.ClassifierDescriptorSVM(), size=ensemble_size,\n",
    "        filter_high_rank=high_rank)\n",
    "    return classifier_ensemble.ClassifierEnsemble.crossValidateByState(\n",
    "        svm_ensemble, df_X, ser_y, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfEval(True, ensemble_size=50, is_randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfEval(False, ensemble_size=50, is_randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clfEval(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfEval(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Classifier by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values by state\n",
    "def plotValuesByState(states, values, stds=None, ylabel=\"percent\"):\n",
    "    if stds is None:\n",
    "        plt.bar(states, values)\n",
    "    else:\n",
    "        plt.bar(states, values, yerr=stds, alpha=0.5)\n",
    "    plt.figure()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"state\")\n",
    "    plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State statistics\n",
    "def plotStateDistributions():\n",
    "    PERCENT = \"percent\"\n",
    "    VALUE = \"value\"\n",
    "    NAME = \"name\"\n",
    "    trinary = TrinaryData(is_averaged=False, is_dropT1=False)\n",
    "    df = pd.DataFrame(trinary.ser_y)\n",
    "    df[VALUE] = list(np.repeat(1, len(df)))\n",
    "    df_group = pd.DataFrame(df.groupby(NAME).count())\n",
    "    dct = {v: k for k, v in trinary.state_dict.items()}\n",
    "    df_group.index = [dct[s] for s in df_group.index]\n",
    "    df_group[PERCENT] = 100*df_group[VALUE] / len(df)\n",
    "    plotValuesByState(df_group.index, df_group[PERCENT])\n",
    "    \n",
    "plotStateDistributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy by state\n",
    "def stateClassificationAccuracy(state, num_iterations=10, is_averaged=False):\n",
    "    NUM_HOLDOUTS = 1\n",
    "    is_dropT1 = is_averaged\n",
    "    trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_dropT1)\n",
    "    df_X = trinary.df_X.copy()\n",
    "    df_X.columns = trinary.features\n",
    "    ser_y = trinary.ser_y\n",
    "    results = []\n",
    "    for _ in range(num_iterations):\n",
    "        test_indices = []\n",
    "        ser_sample = ser_y[ser_y == state].sample(n=NUM_HOLDOUTS)\n",
    "        test_indices.extend(list(ser_sample.index))\n",
    "        train_indices = list(set(df_X.index).difference(test_indices))\n",
    "        svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "            classifier_ensemble.ClassifierDescriptorSVM(), size=30,\n",
    "            filter_high_rank=1500,\n",
    "            classes=list(ser_y.values))\n",
    "        svm_ensemble.fit(df_X.loc[train_indices, :], ser_y.loc[train_indices])\n",
    "        results.append(svm_ensemble.score(df_X.loc[test_indices, :], ser_y[test_indices]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotStateAccuracies(is_averaged=True):\n",
    "    is_dropT1 = is_averaged\n",
    "    trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_dropT1)\n",
    "    states = list(trinary.state_dict.values())\n",
    "    avgs = []\n",
    "    stds = []\n",
    "    for state in states:\n",
    "        values = stateClassificationAccuracy(state, is_averaged=is_averaged)\n",
    "        avgs.append(np.mean(values))\n",
    "        stds.append(np.std(values))\n",
    "    plotValuesByState(list(trinary.state_dict.keys()), avgs, stds=stds, ylabel=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotStateAccuracies(is_averaged=True)\n",
    "plotStateAccuracies(is_averaged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    is_averaged = False\n",
    "    df = df_confuse.applymap(lambda v: np.nan if v <= 0.2 else 1)\n",
    "    df.columns = [c - 0.5 for c in df.columns]\n",
    "    trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_averaged)\n",
    "    states = trinary.ser_y.values\n",
    "    state_colors = [\"grey\", \"orange\", \"green\", \"pink\", \"peru\", \"greenyellow\"]\n",
    "    heatmap = plt.pcolor(df.T, cmap='jet')\n",
    "    #fig = heatmap.get_figure()\n",
    "    #axes = fig.get_axes()[0]\n",
    "    #yaxis = axes.get_yaxis()\n",
    "    #xv = [x + 0.5 for x in range(len(df.T.columns))]\n",
    "    #yv = [y + 0.5 for y in range(len(df.T))]\n",
    "    #plt.xticks(xv)\n",
    "    #plt.yticks(yv)\n",
    "    positions = [p - 0.5 for p in range(-1, len(states))]\n",
    "    labels = [str(int(c-.5)) if c >= 0 else \"\" for c in positions]\n",
    "    plt.yticks(positions, labels)\n",
    "    for idx, state in enumerate(states):\n",
    "        color = state_colors[state]\n",
    "        plt.scatter(idx, [-1], color=color)\n",
    "    #plt.colorbar(heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_averaged = True\n",
    "trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_averaged)\n",
    "svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "            classifier_ensemble.ClassifierDescriptorSVM(), size=50,\n",
    "            filter_high_rank=15)\n",
    "ser_pred = svm_ensemble.makeInstancePredictionDF(trinary.df_X, trinary.ser_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text plotplot predicted vs. actual for values in each state\n",
    "is_averaged = False\n",
    "predicted_states = ser_pred.values\n",
    "trinary = TrinaryData(is_averaged=is_averaged, is_dropT1=is_averaged)\n",
    "states = trinary.ser_y.values\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter([-1,80], [-1,7])\n",
    "for obs in range(len(values)):\n",
    "    _ = plt.text(obs, values[obs], \"%d\" % states[obs], fontsize=16)\n",
    "plt.xlim([0, 75])\n",
    "plt.ylim([-0.5, 5.5])\n",
    "_ = plt.xlabel(\"Observation\", fontsize=18)\n",
    "_ = plt.ylabel(\"Predicted State\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023356070868846144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability of the misclassifications being for adjacent states\n",
    "trinary = TrinaryData(is_averaged=False, is_dropT1=False)\n",
    "df_X = trinary.df_X.copy()\n",
    "df_X.columns = trinary.features\n",
    "svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "            classifier_ensemble.ClassifierDescriptorSVM(), size=50,\n",
    "            filter_high_rank=15,\n",
    "        )\n",
    "svm_ensemble.calcAdjStateProbTail(df_X, trinary.ser_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trinary.df_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "1. Find the probability of having at least 8 of the 10 misclassifications be in adjacent states. This is a generalized binomial where the $q_i = P(s_i  \\in \\{n_i, p_i \\})$, where $s_i$ is the state for observation $i$, \n",
    "$n_i$ is the next state for $i$, and $p_i$ is the state before $i$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
