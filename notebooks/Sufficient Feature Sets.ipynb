{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sufficient Feature Sets\n",
    "A sufficient feature set is a set of genes that, when used as features, results in a high accuracy classifier for a state. The genes in a classification group may well be surrogates for transcription modules or programs. This can be exposed by looking for transcription factors common across groups for a single state. This analysis was priimarily conducted in conjunction with the presentation on May, 15, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues**\n",
    "1. Missing the file fit_result.xlsx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Features by Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import init\n",
    "import common.constants as cn\n",
    "import common_python.constants as ccn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/xstate/data/fit_result.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f4b5951f7fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mSTATES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSER_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_result.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mDF_FIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_result_tf.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mDF_FIT_TF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mfile_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;31m# We have to let unknown file formats pass through here, as some ancient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36minspect_format\u001b[0;34m(path, content)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/xstate/data/fit_result.xlsx'"
     ]
    }
   ],
   "source": [
    "# These are the \"long\" data that have individual replications, not averages\n",
    "PROVIDER = DataProvider()\n",
    "PROVIDER.do()\n",
    "TRINARY = TrinaryData(is_averaged=False, is_dropT1=False)  # Trinary data\n",
    "DF_X = TRINARY.df_X\n",
    "SER_Y = TRINARY.ser_y\n",
    "STATES = SER_Y.unique()\n",
    "path = os.path.join(cn.DATA_DIR, \"fit_result.xlsx\")\n",
    "DF_FIT = pd.read_excel(path)\n",
    "path = os.path.join(cn.DATA_DIR, \"fit_result_tf.xlsx\")\n",
    "DF_FIT_TF = pd.read_excel(path)\n",
    "DF_FIT_TF.head()\n",
    "TFs = list(DF_FIT_TF[\"feature\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PROVIDER.df_trn_signed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transcription factors\n",
    "TFS = PROVIDER.df_trn_unsigned[cn.TF].unique()\n",
    "TFS = list(set(TFS).intersection(TRINARY.df_X.columns))\n",
    "len(TFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Genes With Transcription Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Data Construction for Sufficient Feature Sets\n",
    "\n",
    "# Group by state and index\n",
    "dfg = DF_FIT.groupby([cn.STATE, cn.INDEX])\n",
    "df_g = pd.DataFrame(dfg.count())\n",
    "df_g[cn.COUNT] = dfg.count()\n",
    "for col in df_g.columns:\n",
    "    if col != cn.COUNT:\n",
    "        del df_g[col]              \n",
    "df_g = df_g.reset_index()\n",
    "df_g[cn.SCORE] = dfg.mean().reset_index()[cn.SCORE]\n",
    "state = 0\n",
    "df = df_g[df_g[cn.STATE] == state]\n",
    "#plt.scatter(df[cn.INDEX], df[cn.SCORE])\n",
    "df_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge = DF_FIT.merge(PROVIDER.df_trn_unsigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct a dataframe that merges classification group with transcription factors\n",
    "df_merge = DF_FIT.merge(PROVIDER.df_trn_unsigned)\n",
    "del df_merge[cn.SIGN]\n",
    "del df_merge[cn.COUNT]\n",
    "df_merge = df_merge.drop_duplicates()\n",
    "df_merge = df_merge.sort_values([cn.STATE, cn.INDEX, cn.TF])\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of accuracies in fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(DF_FIT_TF[DF_FIT_TF[\"state\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotSES(state, df_fit):\n",
    "    \"\"\"\n",
    "    :param int state:\n",
    "    :param pd.DataFrame df_fit:\n",
    "      columns\n",
    "        cn.STATE\n",
    "        cn.INDEX/cn.GROUP\n",
    "        cn.GENE_ID/ccn.FEATURE\n",
    "        cn.SCORE\n",
    "    \"\"\"\n",
    "    df_fit = df_fit.copy()\n",
    "    if not cn.INDEX in df_fit.columns:\n",
    "        df_fit[cn.INDEX] = df_fit[cn.GROUP]\n",
    "    if not cn.GENE_ID in df_fit.columns:\n",
    "        df_fit[cn.GENE_ID] = df_fit[ccn.FEATURE]\n",
    "    df = df_fit[df_fit[cn.STATE] == state]\n",
    "    df = df.copy()\n",
    "    dfg = df.groupby(cn.INDEX).mean()\n",
    "    scores = dfg[cn.SCORE].tolist()\n",
    "    #scores = [f[\"score\"] for _, f in df_fit_result.iterrows() if f[\"state\"] == state]\n",
    "    scores = sorted(scores, reverse=True)\n",
    "    xv = range(30)\n",
    "    plt.scatter(xv, scores[0:len(xv)])\n",
    "    if state == 0:\n",
    "        plt.ylabel(\"accuracy\")\n",
    "    if state % 2 == 1:\n",
    "        plt.yticks([])\n",
    "    plt.ylim([0.5, 1])\n",
    "    #pos = int(0.6*len(scores))\n",
    "    plt.text(15, 0.6, str(state))\n",
    "    plt.xticks([])\n",
    "    # plt.title(\"State %d\" % state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_FIT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis of drop in accuracies of CFS for all genes and transcription factors\n",
    "for df in [DF_FIT, DF_FIT_TF]:\n",
    "    plt.figure()\n",
    "    for state in STATES:\n",
    "        plt.subplot(3, 2, state+1)\n",
    "        plotSES(state, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Transcription Factor by State\n",
    "This analysis examines commonalities in the transcription factors of classification groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tf = df_merge.copy()\n",
    "del df_tf[cn.GENE_ID]\n",
    "df_tf[cn.GROUP] = df_tf[cn.INDEX]\n",
    "del df_tf[cn.INDEX]\n",
    "df_tf = df_tf.drop_duplicates()\n",
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STATE = 0\n",
    "df_plot = df_tf[df_tf[cn.STATE] == STATE]\n",
    "df_plot = df_plot.copy()\n",
    "df_plot.index = [str(i) for i in df_plot.index]\n",
    "del df_plot[cn.STATE]\n",
    "df_plot = df_plot.pivot(index=cn.GROUP, columns=cn.TF, values=cn.SCORE)\n",
    "df_plot.columns = [str(c) for c in df_plot.columns]\n",
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tf[df_tf[cn.STATE] == state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotTFByGroup(df_tf, state, min_score=0.9):\n",
    "    # Construct the data\n",
    "    df_plot = df_tf[df_tf[cn.STATE] == state]\n",
    "    df_plot = df_plot.copy()\n",
    "    del df_plot[cn.STATE]\n",
    "    df_plot = df_plot.pivot(index=cn.GROUP, columns=cn.TF, values=cn.SCORE)\n",
    "    df_plot.columns = [str(c) for c in df_plot.columns]\n",
    "    # Do the plot\n",
    "    if False:\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks(np.arange(len(df_plot.index))+0.5)\n",
    "        ax.set_xticklabels(df_plot.index, rotation=0)\n",
    "        ax.set_yticks(np.arange(len(df_plot.columns))+0.5)\n",
    "        ax.set_yticklabels(df_plot.columns, rotation=0)\n",
    "        ax.set_xlabel(cn.GROUP)\n",
    "        ax.set_ylabel(\"transcription factor\")\n",
    "        #heatmap = plt.pcolor(df_plot.T)\n",
    "        #_ = plt.colorbar(heatmap)\n",
    "    df_plot = df_plot.applymap(lambda v: 0 if np.isnan(v) else v)\n",
    "    cg = seaborn.clustermap(df_plot.T, row_cluster=True, col_cluster=True, mask=df_plot.T.applymap(lambda v: v <0.9))\n",
    "    plt.title(\"State: %d\" % state)\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Transcription Factor\")\n",
    "    \n",
    "plotTFByGroup(df_tf, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations of Transcription Factors\n",
    "To identify gene programs, look for correlations among transcription factors by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotCorr(state):\n",
    "    indices = SER_Y[SER_Y == state].index\n",
    "    df_X = DF_X.loc[indices, :]\n",
    "    util_plots.plotCorr(df_X[TFS], is_yticklabels=True, is_xticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = DataProvider()\n",
    "provider.do()\n",
    "len(provider.tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PROVIDER.df_go_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = [\"Rv3417c\", \"Rv0238\"]\n",
    "df_xpln = PROVIDER.df_go_terms[PROVIDER.df_go_terms[cn.GENE_ID].isin(genes)]\n",
    "dff = df_xpln.set_index(cn.GENE_ID)\n",
    "for gene_id in df_xpln[cn.GENE_ID]:\n",
    "    print(\"%s: %s\" % (gene_id, dff.loc[gene_id, cn.GO_TERM]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in STATES:\n",
    "    plotCorr(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of TF Sufficient Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following plots indicate the classification set features of TFs that are sufficient to\n",
    "# distinguish each state.\n",
    "# By definitions, these are non-overlapping.\n",
    "df_tf = DF_FIT_TF.copy()\n",
    "df_tf[cn.TF] = df_tf[ccn.FEATURE]\n",
    "for state in STATES:\n",
    "    plotTFByGroup(df_tf, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Analysis of Eliza's gene\n",
    "1. Determine if TFs in SFSs are in common correlation groups\n",
    "1. Observe that TF SFS don't have overlapping members.\n",
    "1. Construct a correlation matrix of TFs in SFS for each state.\n",
    "1. TF equvalence analysis.\n",
    "   1. Given a SFS $S = \\{s_{1}, \\cdots, s_{n}\\}$.\n",
    "   1. Let $A_S$ be the accuracy of the classifier using the features $S$. Further, let $S-s_m+s = S - \\{s_m\\} \\cup {s}$.\n",
    "   1. Calculate $max \\left ( 0, 1 - \\frac{|A_S - A_{S-s_m+s}|}{A_S - A_{S-s_m}} \\right )$ for all $S$ and $s \\notin S$.\n",
    "   The SFS-correlation with feature $s_m$ and a feature outside the set $s$ is 1 minus the change in classification accuracy if $s$ is substituted for $s_m$.\n",
    "   1. An alternative is the fractional increase in accuracy by replacing $s_m$ with $s$. Or, Calculate \n",
    "   $\\frac{A_{S-s_m+s} - A_S}{A_S - A_{S-s_m}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special gene analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = [\"Rv1477\", \"Rv3717\", \"Rv0129c\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_FIT[DF_FIT[cn.GENE_ID].isin(genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSCSFromDF(state, index):\n",
    "    df = DF_FIT[DF_FIT[cn.STATE]==state]\n",
    "    return df[df[cn.INDEX] == index]\n",
    " \n",
    "print(getSCSFromDF(3, 7))\n",
    "print(getSCSFromDF(5, 21))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
