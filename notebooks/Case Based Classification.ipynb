{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE BASED CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook develops the idea of case base classiication (cb-clf). This involves:\n",
    "1. Identify sets of feature that provide good classification accuracy. There may be many.\n",
    "1. Given a new feature vector, provide evidence for the difference classes to which it may belong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **feature** is an atribtue of the data, like a Gene. A feature set is a collection of genes.\n",
    "We typically write this as Rv3246c+Rv3260c.\n",
    "\n",
    "A **feature vector** is a set of features with a value assigned. We are dealing with trinary values: -1 (under expressed),\n",
    "+1 (over expressed), 0 (otherwise).\n",
    "We typically write this as\n",
    "Rv3246c[-1]+Rv3260c[0].\n",
    "\n",
    "A **case** is a feature vector that effectively distinguishes between expression states (classes).\n",
    "\n",
    "Cases are obtained from decision trees by examining nodes to see if their *impurity* (class distinctions) are statistically\n",
    "significant.\n",
    "\n",
    "Decision trees are obtained by running the Random Forest Classsification Algorithm.\n",
    "This is done separately for each expression state.\n",
    "So, in our data, there are 6 sets of cases.\n",
    "\n",
    "Classifications are evaluated for new gene expression data by:\n",
    "* Setup\n",
    "   1. Construct cases for each expression state.\n",
    "   \n",
    "* Evaluation of a data set\n",
    "   1. Create trinary data\n",
    "   1. For each expression state\n",
    "      1. Find applicable cases\n",
    "      1. Plot their significance level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import init\n",
    "import common.constants as cn\n",
    "import common_python.constants as ccn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "from common_python.classifier import feature_analyzer\n",
    "from common_python.classifier import feature_set_collection\n",
    "from common_python.util import util\n",
    "from common import transform_data\n",
    "from common_python.classifier.feature_set import FeatureSet, FeatureVector\n",
    "from common import trinary_data\n",
    "from common_python.classifier.cc_case.case_core import FeatureVectorStatistic, Case\n",
    "from common_python.classifier.cc_case.case_collection import CaseCollection\n",
    "from common_python.classifier.cc_case.case_multi_collection import CaseMultiCollection\n",
    "from common_python.classifier.cc_case.case_builder import CaseBuilder\n",
    "from common_python.util.persister import Persister\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "REPO_PATH = util.findRepositoryRoot(\"xstate\")\n",
    "DATA_PATH = os.path.join(REPO_PATH, \"data\")\n",
    "DF_X_PATH = os.path.join(DATA_PATH, \"feature_values_regulators.csv\")\n",
    "DF_X_FULL_PATH = os.path.join(DATA_PATH, \"feature_values.csv\")\n",
    "SER_Y_PATH = os.path.join(DATA_PATH, \"class_values.csv\")\n",
    "SERIALIZE_FILE = os.path.join(DATA_PATH, \"case_based_classification.csv\")\n",
    "PERSISTER_PATH = \"case_based_classification.pcl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "DF_X = util.deserializePandas(DF_X_FULL_PATH)\n",
    "SER_Y = util.deserializePandas(SER_Y_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the \"long\" data that have individual replications, not averages. And, only using TFs.\n",
    "STATES = SER_Y.unique()\n",
    "FEATURES_NAMES = DF_X.columns.tolist()\n",
    "NUM_TREE = 20000\n",
    "PROVIDER = DataProvider()\n",
    "PROVIDER.do()\n",
    "SER_DESC = PROVIDER.df_go_terms.set_index(cn.GENE_ID)\n",
    "SER_DESC = SER_DESC[\"GO_Term\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case data\n",
    "persister = Persister(PERSISTER_PATH)\n",
    "if persister.isExist():\n",
    "    CASE_MULTI_COLLECTION = persister.get()\n",
    "else:\n",
    "    if os.path.isfile(SERIALIZE_FILE):\n",
    "        CASE_MULTI_COLLECTION = CaseMultiCollection.deserialize(SERIALIZE_FILE, df_X_path=DF_X_PATH, ser_y_path=SER_Y_PATH)\n",
    "    else:\n",
    "        CASE_MULTI_COLLECTION = CaseBuilder.make(DF_X, SER_Y, n_estimators=NUM_TREE, n_jobs=-1)  # Run on all processors\n",
    "        CASE_MULTI_COLLECTION.serialize(SERIALIZE_FILE, df_X_path=DF_X_PATH, ser_y_path=SER_Y_PATH)\n",
    "    persister.set(CASE_MULTI_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The data consistent of individual replicas of read counts at 26 times.\n",
    "1. Times are labelled with six states, as defined in ``STATE_DCT``.\n",
    "1. Raw expression values of normalized w.r.t. time 0 (normal) and transformed as log2 so that there are\n",
    "25 normalized times that are trinary values defined as:\n",
    "   * -1 if < -1\n",
    "   * 1 if > 1\n",
    "   * 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SER_DESC.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [(g in DF_X.columns) and (SER_DESC.loc[g].find(\"fatty acid\") > 0) for g in SER_DESC.index]\n",
    "SER_DESC[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_DCT = {}\n",
    "STATE_DCT[0] = \"Normoxia\"\n",
    "STATE_DCT[1] = \"Transition\"\n",
    "STATE_DCT[2] = \"Stage II\"\n",
    "STATE_DCT[3] = \"Stage 1a\"\n",
    "STATE_DCT[4] = \"Stage 1b\"\n",
    "STATE_DCT[5] = \"Resuscitation\"\n",
    "STATE_DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_y = SER_Y[SER_Y.index.str.contains(\"\\.0\")]\n",
    "ser_y.index = range(len(ser_y))\n",
    "plt.scatter(ser_y.index, ser_y.values)\n",
    "plt.ylabel(\"state\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.title(\"State Of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_DATA = trinary_data.getSampleData()\n",
    "DF_AM_MDM = SAMPLE_DATA.AM_MDM.T\n",
    "DF_AW = SAMPLE_DATA.AW.T\n",
    "DF_GALAGAN = SAMPLE_DATA.galagan.T\n",
    "DF_SHERMAN = SAMPLE_DATA.sherman.T\n",
    "DF_RUSTAD = SAMPLE_DATA.rustad.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullProfile(ser_X, title=\"\", terms=[\"hypoxia\", \"fatty acid\"], **kwargs):\n",
    "    \"\"\"\n",
    "    Creates a classification profile for the feature vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ser_X: Series (feature vector)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        columns: class\n",
    "        index: FeatureVector\n",
    "        values: num_zero\n",
    "    \"\"\"\n",
    "    feature_vector = FeatureVector.make(ser_X)\n",
    "    if terms is None:\n",
    "        multi= CASE_MULTI_COLLECTION\n",
    "    else:\n",
    "        multi = CASE_MULTI_COLLECTION.select(CaseCollection.selectByDescription, ser_desc=SER_DESC, terms=terms)\n",
    "    df = multi.plotBars(feature_vector=feature_vector, title=title, **kwargs)\n",
    "# TESTING\n",
    "ser_X = DF_X.loc[\"T2.1\"]\n",
    "terms = [\"hypoxia\", \"fatty acid\"]\n",
    "fullProfile(ser_X, figsize=(3,3), terms=[\"hypoxia\"], title=\", \".join(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AW.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(df, num_row, num_col, is_plot=True, figsize=(10, 8), **kwargs):\n",
    "    \"\"\"\n",
    "    Positive cases for instances.\n",
    "    \n",
    "    df: pd.DataFrame\n",
    "        columns: instances\n",
    "        rows: genes\n",
    "    \"\"\"\n",
    "    df = df.T\n",
    "    indices = list(df.index)\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=figsize)\n",
    "    for irow in range(num_row):\n",
    "        for icol in range(num_col):\n",
    "            ax = axes[irow][icol]\n",
    "            idx = irow*num_col + icol\n",
    "            instance = indices[idx]\n",
    "            feature_vector = FeatureVector(df.loc[instance, :])\n",
    "            CASE_MULTI_COLLECTION.plotBars(feature_vector=feature_vector, is_plot=False,\n",
    "                                           title=instance, fontsize=8, ax=ax, **kwargs)\n",
    "    if not is_plot:\n",
    "        plt.close()\n",
    "    \n",
    "# Tests\n",
    "profile(DF_AW, 3, 2, max_sl=0.0001, is_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a maximum significance level $\\alpha$, a sample size of $N$, and null distribution that is Binomial in $(N, p)$,\n",
    "what is the minimum sample size?\n",
    "\n",
    "We want $N$ such that $P(n = N) = P(n = 0) \\leq \\alpha$.\n",
    "That is, $\\alpha \\geq p^N \\equiv \\frac{log(\\alpha)}{log(p)} \\leq N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluations of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{STATE_DCT[k]: len(c) for k, c in CASE_MULTI_COLLECTION.collection_dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in [\"\\.0\", \"\\.1\", \"\\.2\"]:\n",
    "    df = DF_X[DF_X.index.str.contains(rep)]\n",
    "    CASE_MULTI_COLLECTION.plotBarsForFeatures(df, 5, 5, suptitle = rep, ser_y=SER_Y, fontsize=8, max_sl=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(DF_AW, 3, 2, max_sl=0.005, xlabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AM, MDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = DF_AM_MDM.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(DF_AM_MDM, 2, 4, max_sl=1e-4, xlabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(DF_GALAGAN, 3, 6, figsize=(14, 10), max_sl=1e-3, xlabel=\"\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sherman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(DF_SHERMAN, 1, 1, figsize=(14, 10), max_sl=0.05, xlabel=\"\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SHERMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rustad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RUSTAD.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in DF_RUSTAD.columns:\n",
    "    fullProfile(DF_RUSTAD[instance], title=instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluations of Samples - Only \"hypoxia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_MANAGER_DCT = copy.deepcopy(CASE_MANAGER_BASE_DCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[m.filterCaseByDescription(SER_DESC, include_terms=[\"hypoxia\"]) for m in CASE_MANAGER_DCT.values()]\n",
    "{k: len(CASE_MANAGER_DCT[k].case_dct) for k in CASE_MANAGER_DCT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a evaluation of the feature vector at the first replication at time T3.\n",
    "instances = [\"T3.0\", \"T3.1\", \"T3.2\"]\n",
    "for instance in instances:\n",
    "    fullProfile(DF_X.loc[instance], title=instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\"T13.0\", \"T13.1\", \"T13.2\"]\n",
    "for instance in instances:\n",
    "    fullProfile(DF_X.loc[instance], title=instance)\n",
    "print(\"State: %s\" % STATE_DCT[SER_Y.loc[\"T13.0\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [ [\"AW_%s_%d\" % (pm, n) for pm in [\"plus\", \"neg\"]] for n in [1, 3, 4]]\n",
    "instances = list(np.array(instances).flatten())\n",
    "for instance in instances:\n",
    "    fullProfile(DF_AW[instance], title=instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AM, MDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [ [\"%s_D20_%d\" % (pm, n) for pm in [\"AM\", \"MDM\"]] for n in [1, 3, 4, 5]]\n",
    "instances = list(np.array(instances).flatten())\n",
    "for instance in instances:\n",
    "    fullProfile(DF_AM_MDM[instance], title=instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use other criteria to select the cases\n",
    "   1. Prefer longer feature vectors since more specific\n",
    "   1. Remove correlated cases\n",
    "   1. Filter feature vectors?\n",
    "   1. Evaluate using counts of pos/neg cases by class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
