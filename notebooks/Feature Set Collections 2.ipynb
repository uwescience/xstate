{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Set Collections 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues**\n",
    "1. missing collection.getEvaluationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init\n",
    "import common.constants as cn\n",
    "import common_python.constants as ccn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "from common_python.classifier import feature_analyzer\n",
    "from common_python.classifier import feature_set_collection\n",
    "from common_python.util import util\n",
    "from common import transform_data\n",
    "from common_python.classifier.feature_set import FeatureSet\n",
    "from common import trinary_data\n",
    "from classifier import util_classifier\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the \"long\" data that have individual replications, not averages. And, only using TFs.\n",
    "PROVIDER = DataProvider()\n",
    "PROVIDER.do()\n",
    "TRINARY = TrinaryData(is_averaged=False, is_dropT1=False, is_regulator=True)  # Trinary data\n",
    "DF_X = TRINARY.df_X\n",
    "SER_Y = TRINARY.ser_y\n",
    "STATES = SER_Y.unique()\n",
    "REGULATORS = DF_X.columns.tolist()\n",
    "DATA_PATH = cn.PROJECT_DIR\n",
    "for directory in [\"data\", \"feature_analyzer\"]:\n",
    "    DATA_PATH = os.path.join(DATA_PATH, directory)\n",
    "DATA_PATH_PAT = os.path.join(DATA_PATH, \"%d\") \n",
    "ANALYZER_DCT = feature_analyzer.deserialize({s: DATA_PATH_PAT % s for s in STATES})\n",
    "ANALYZERS = ANALYZER_DCT.values()\n",
    "COLLECTION_DCT = {s: feature_set_collection.FeatureSetCollection.deserialize(DATA_PATH_PAT % s) for s in STATES}\n",
    "_ = [c.df_fv for c in COLLECTION_DCT.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Serialize the collections\n",
    "if False:\n",
    "    for state in STATES:\n",
    "        COLLECTION_DCT[state].serialize(DATA_PATH_PAT % state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE_ID</th>\n",
       "      <th>GO_Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P9WKY5</td>\n",
       "      <td>host cell nucleus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rv0001</td>\n",
       "      <td>DNA replication initiation---dephosphorylation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rv0002</td>\n",
       "      <td>extracellular region---cell wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rv0003</td>\n",
       "      <td>double-strand break repair---cytosol---plasma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rv0005</td>\n",
       "      <td>DNA topological change---growth---magnesium io...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GENE_ID                                            GO_Term\n",
       "0  P9WKY5                                  host cell nucleus\n",
       "1  Rv0001  DNA replication initiation---dephosphorylation...\n",
       "2  Rv0002                   extracellular region---cell wall\n",
       "3  Rv0003  double-strand break repair---cytosol---plasma ...\n",
       "4  Rv0005  DNA topological change---growth---magnesium io..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROVIDER.df_go_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA = trinary_data.getSampleData()\n",
    "DF_AM = SAMPLE_DATA.AM_MDM\n",
    "DF_AW = SAMPLE_DATA.AW\n",
    "DF_GALAGAN = SAMPLE_DATA.galagan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set Collection Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def histograms(ser_X, title=\"\", terms=[\"hypoxia\"], **kwargs):\n",
    "    ncol = 3\n",
    "    nrow = 2\n",
    "    fset_selector = lambda f: util_classifier.countTerms(f, terms) > 0\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(16, 12))\n",
    "    for idx, state in enumerate(COLLECTION_DCT.keys()):\n",
    "        row = int(idx/ncol)\n",
    "        col = idx % ncol\n",
    "        if idx == 5:\n",
    "            is_plot=False\n",
    "        else:\n",
    "            is_plot=False\n",
    "        COLLECTION_DCT[state].plotEvaluateHistogram(ser_X, ax=axes[row, col], fset_selector=fset_selector,\n",
    "                                                   title=\"%d\" % state, is_plot=False, **kwargs)\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in DF_AM.index:\n",
    "    ser_X = DF_AM.loc[instance, :]\n",
    "    #histograms(ser_X, title=instance, ylim=[0,10], max_sl=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in DF_GALAGAN.index:\n",
    "    ser_X = DF_GALAGAN.loc[instance, :]\n",
    "    #histograms(ser_X, title=instance, max_sl=0.01, ylim=[0, 10], terms=[\"hypoxia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Analysis\n",
    "Only include genes that have GO terms hypoxia, lipid, fatty acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fullEvaluate(ser_X, title=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Plots all evaluate profiles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ser_X: pd.DataFrame\n",
    "        Feature vector for a single instance\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    fset_selector = lambda f: util_classifier.countTerms(f, [\"hypoxia\", \"lipid\", \"fatty acid\"]) > 1\n",
    "    fset_selector = lambda f: True\n",
    "    max_sl = 0.001\n",
    "    num_row = 2\n",
    "    num_col = 3\n",
    "    fig, axes = plt.subplots(num_row, num_col,\n",
    "      figsize=(16, 10))\n",
    "    for idx, state in enumerate(STATES):\n",
    "        row = int(idx/num_col)\n",
    "        col = idx % num_col\n",
    "        collection = COLLECTION_DCT[state]\n",
    "        if row == 0:\n",
    "            label_xoffset = -0.2\n",
    "        else:\n",
    "            label_xoffset = 0.2\n",
    "        collection.plotEvaluate(ser_X, fset_selector=fset_selector, num_fset=100,\n",
    "            ax=axes[row, col], is_plot=False, max_sl=max_sl,\n",
    "            title = \"State %d\" % idx,\n",
    "            label_xoffset=label_xoffset, **kwargs)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reportEvaluate(ser_X, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes a file with the report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ser_X: pd.DataFrame\n",
    "        Feature vector for a single instance\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    fset_selector = lambda f: util_classifier.countTerms(f, [\"hypoxia\", \"lipid\", \"fatty acid\"]) > 1\n",
    "    fset_selector = lambda f: True\n",
    "    max_sl = 0.001\n",
    "    dfs = []\n",
    "    for idx, state in enumerate(STATES):\n",
    "        collection = COLLECTION_DCT[state]\n",
    "        df = collection.getEvaluationDF(ser_X, fset_selector=fset_selector, num_fset=100,\n",
    "            max_sl=max_sl, **kwargs)\n",
    "        df[cn.STATE] = state\n",
    "        dfs.append(df)\n",
    "    df_report = pd.concat(dfs)\n",
    "    return df_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeatureSetCollection' object has no attribute 'getEvaluationDF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e4a45584d2d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDF_AM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mser_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF_AM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreportEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-19b47ac4956d>\u001b[0m in \u001b[0;36mreportEvaluate\u001b[0;34m(ser_X, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOLLECTION_DCT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         df = collection.getEvaluationDF(ser_X, fset_selector=fset_selector, num_fset=100,\n\u001b[0m\u001b[1;32m     21\u001b[0m             max_sl=max_sl, **kwargs)\n\u001b[1;32m     22\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeatureSetCollection' object has no attribute 'getEvaluationDF'"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for instance in DF_AM.index:\n",
    "    ser_X = DF_AM.loc[instance, :]\n",
    "    df = reportEvaluate(ser_X)\n",
    "    df[\"instance\"] = instance\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(\"AM.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in DF_GALAGAN.index:\n",
    "    ser_X = DF_GALAGAN.loc[instance, :]\n",
    "    #fullEvaluate(ser_X, title=instance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
