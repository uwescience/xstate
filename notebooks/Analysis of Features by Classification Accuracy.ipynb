{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Features by Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init\n",
    "import common.constants as cn\n",
    "from common.trinary_data import TrinaryData\n",
    "import classifier.main_multi_classifier_feature_optimizer as main\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRINARY = TrinaryData(is_averaged=False, is_dropT1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_dct = main.getFitResultFromPersister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [1, 1, 3, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 4, 3, 2, 2, 2, 2, 4, 1, 5, 4, 2, 3, 3, 1, 1, 2, 1]\n",
      "   [1.0, 1.0, 1.0, 0.9933333333333333, 1.0, 1.0, 1.0, 0.9966666666666667, 1.0, 0.8266666666666667, 0.9966666666666667, 1.0, 1.0, 1.0, 1.0, 0.8566666666666667, 0.99, 0.9933333333333333, 0.8266666666666667, 1.0, 0.5, 1.0, 1.0, 0.9966666666666667, 1.0, 1.0, 0.5, 0.5, 0.6633333333333333, 0.5]\n",
      "   [1, 1, 117, 2337, 8, 41, 34, 2328, 38, 2322, 46, 52, 70, 72, 727, 2305, 2303, 2301, 2299, 83, 2293, 173, 767, 2283, 150, 483, 2275, 2274, 2273, 2271]\n",
      "1: [5, 1, 3, 2, 2, 3, 2, 2, 2, 2, 7, 2, 2, 5, 4, 3, 8, 3, 4, 3, 5, 3, 6, 2, 2, 3, 4, 6, 6, 3]\n",
      "   [1.0, 0.9833333333333333, 0.99, 0.9666666666666667, 0.9833333333333333, 0.98, 0.9566666666666667, 0.9733333333333334, 0.96, 0.9633333333333334, 0.98, 0.9733333333333334, 0.9566666666666667, 0.99, 0.9766666666666667, 0.9566666666666667, 0.98, 0.99, 0.9633333333333334, 0.9833333333333333, 0.9633333333333334, 0.9833333333333333, 0.9866666666666667, 0.9366666666666666, 0.96, 0.9666666666666667, 0.9566666666666667, 0.9433333333333334, 0.99, 0.96]\n",
      "   [702, 2338, 2336, 2335, 2333, 2332, 2328, 2325, 2325, 2322, 2319, 2312, 2311, 2308, 2304, 2299, 2295, 2289, 2285, 2282, 2279, 2274, 2270, 2265, 2262, 2261, 2256, 2253, 2247, 2243]\n",
      "2: [2, 4, 3, 2, 1, 3]\n",
      "   [0.92, 0.9066666666666666, 0.9333333333333333, 0.9, 0.91, 0.8933333333333333]\n",
      "   [2342, 2340, 2336, 2334, 2333, 2330]\n"
     ]
    }
   ],
   "source": [
    "for cl in fit_result_dct.keys():\n",
    "    length_stg = str([len(fr.sels) for fr in fit_result_dct[cl]])\n",
    "    score_stg = str([fr.sels_score for fr in fit_result_dct[cl]])\n",
    "    n_eval_stg = str([fr.n_eval for fr in fit_result_dct[cl]])\n",
    "    print(\"%d: %s\\n   %s\\n   %s\" % (cl, length_stg, score_stg, n_eval_stg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
